import asyncio
import random
import numpy as np
import cv2
import dlib
from math import hypot, tanh
# YOLO ì–¼êµ´ ê°ì§€ í•¨ìˆ˜ ì„í¬íŠ¸
from src.face_detection import detect_faces_yolo
import base64 # base64 ì¸ì½”ë”©ì„ ìœ„í•´ ì¶”ê°€

# dlib ì–¼êµ´ ëœë“œë§ˆí¬ ê°ì§€ê¸° ì´ˆê¸°í™” (ê²½ë¡œëŠ” í™˜ê²½ì— ë§ê²Œ ì¡°ì • í•„ìš”)
try:
    predictor_path = "assets/models/shape_predictor_68_face_landmarks.dat"
    detector = dlib.get_frontal_face_detector()
    predictor = dlib.shape_predictor(predictor_path)
    dlib_available = True
except Exception as e:
    print(f"âš ï¸ Dlib ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. ëœë“œë§ˆí¬ ê¸°ë°˜ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
    dlib_available = False
    detector = None
    predictor = None

# í‘œì • ì ìˆ˜ ê³„ì‚°ì„ ìœ„í•œ í´ë˜ìŠ¤
class ExpressionDetector:
    def __init__(self):
        # EAR ê³„ì‚°ì„ ìœ„í•œ ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ ì •ì˜
        self.L_EYE_START = 36
        self.L_EYE_END = 41
        self.R_EYE_START = 42
        self.R_EYE_END = 47
        # ìœ™í¬ ë° ê¸°ìš¸ê¸° ê´€ë ¨ ì†ì„± ì œê±°

    # í•¨ìˆ˜ ì´ë¦„ ë³€ê²½ ë° ë¡œì§ ìˆ˜ì •: get_expression_change -> get_expression_score
    def get_expression_score(self, face_idx, landmarks, detection_mode):
        """í‘œì • ì ìˆ˜ ê³„ì‚° (ì§€ì •ëœ ëª¨ë“œ ê¸°ì¤€ ì ˆëŒ€ ì ìˆ˜)"""
        if not dlib_available or landmarks is None:
            return 0.0 # dlib ì‚¬ìš© ë¶ˆê°€ ë˜ëŠ” ëœë“œë§ˆí¬ ì—†ìœ¼ë©´ 0ì  ë°˜í™˜

        current_score = 0.0
        if detection_mode == 'smile' or detection_mode == 'big_smile':
            current_score = self._measure_smile(landmarks)
        elif detection_mode == 'open_mouth':
            current_score = self._measure_mouth_openness(landmarks)
        elif detection_mode == 'surprise':
            current_score = self._measure_surprise(landmarks)
        elif detection_mode == 'ugly_face':
            current_score = self._measure_ugly_face(landmarks)
        # refreshing_wink ì¡°ê±´ ë¶„ê¸° ì œê±°

        # 0~1 ì‚¬ì´ ê°’ìœ¼ë¡œ ì •ê·œí™” (ê° ì¸¡ì • í•¨ìˆ˜ì˜ ë°˜í™˜ê°’ ë²”ìœ„ ê³ ë ¤ í•„ìš”)
        # ê° ì¸¡ì • í•¨ìˆ˜ì—ì„œ 0~1 ë²”ìœ„ë¡œ ë°˜í™˜í•˜ë„ë¡ í•¨
        current_score = min(1.0, max(0.0, current_score))

        return current_score

    # --- í‘œì • ì¸¡ì • í•¨ìˆ˜ë“¤ (ì •ê·œí™” ê¸°ì¤€ ë³€ê²½ ë° ìŠ¤ì¼€ì¼ë§/ê°€ì¤‘ì¹˜ ì¬ì¡°ì •) ---
    def _calculate_iod(self, landmarks):
        """ëˆˆ ì‚¬ì´ ê±°ë¦¬(Inter-Ocular Distance) ê³„ì‚° (ëœë“œë§ˆí¬ 36, 45)"""
        if landmarks is None or len(landmarks) < 68: return 0.0
        eye_left = landmarks[36]
        eye_right = landmarks[45]
        dist = hypot(eye_right[0] - eye_left[0], eye_right[1] - eye_left[1])
        return dist if dist > 0 else 1.0 # 0 ë°©ì§€

    def _calculate_ear(self, landmarks, eye_start_idx, eye_end_idx):
        """ëˆˆ ëœ¨ê¸° ë¹„ìœ¨ (Eye Aspect Ratio) ê³„ì‚°"""
        if landmarks is None or len(landmarks) < 68: return 0.0
        # ìˆ˜ì§ ê±°ë¦¬ ê³„ì‚° (ëˆˆêº¼í’€ ìœ„ì•„ë˜ ëœë“œë§ˆí¬ 2ìŒ ì‚¬ìš©)
        v1 = hypot(landmarks[eye_start_idx+1][0] - landmarks[eye_end_idx][0], landmarks[eye_start_idx+1][1] - landmarks[eye_end_idx][1])
        v2 = hypot(landmarks[eye_start_idx+2][0] - landmarks[eye_end_idx-1][0], landmarks[eye_start_idx+2][1] - landmarks[eye_end_idx-1][1])
        # ìˆ˜í‰ ê±°ë¦¬ ê³„ì‚° (ëˆˆ ì–‘ë ëœë“œë§ˆí¬)
        h = hypot(landmarks[eye_start_idx][0] - landmarks[eye_start_idx+3][0], landmarks[eye_start_idx][1] - landmarks[eye_start_idx+3][1])
        if h == 0: return 0.0
        ear = (v1 + v2) / (2.0 * h)
        return ear

    def _measure_smile(self, landmarks):
        """ë¯¸ì†Œ ì •ë„ ì¸¡ì • - IOD ì •ê·œí™”, ëˆˆ ê°ê¹€ ê³ ë ¤, ë¬´í‘œì • ì ìˆ˜ ê°œì„ """
        if landmarks is None or len(landmarks) < 68: return 0.0
        iod = self._calculate_iod(landmarks)

        # 1. ì… íŠ¹ì§• ê³„ì‚°
        mouth_left = landmarks[48]; mouth_right = landmarks[54]; mouth_top = landmarks[51]
        mouth_width = hypot(mouth_right[0] - mouth_left[0], mouth_right[1] - mouth_left[1])
        corner_lift_raw = mouth_top[1] - (mouth_left[1] + mouth_right[1]) / 2
        normalized_width = mouth_width / iod
        normalized_corner_lift = corner_lift_raw / iod

        # ì… ì ìˆ˜ ìŠ¤ì¼€ì¼ë§ (íŠœë‹ í•„ìš”)
        mouth_score = (normalized_width * 0.6 + normalized_corner_lift * 0.4) * 1.3

        # 2. ëˆˆ íŠ¹ì§• ê³„ì‚° (ëˆˆ ê°ê¹€ ì •ë„) - EAR ì‚¬ìš©
        left_ear = self._calculate_ear(landmarks, self.L_EYE_START, self.L_EYE_END)
        right_ear = self._calculate_ear(landmarks, self.R_EYE_START, self.R_EYE_END)
        avg_ear = (left_ear + right_ear) / 2.0

        # ëˆˆ ê°ê¹€ ì ìˆ˜ ìŠ¤ì¼€ì¼ë§ (EAR ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½, EARì´ ì‘ì„ìˆ˜ë¡ ì ìˆ˜ ë†’ìŒ)
        # (íŠœë‹ í•„ìš”) í‰ê·  EAR 0.25 ì •ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ, 0.15 ì´í•˜ë©´ 1ì  ê°€ê¹ê²Œ
        eye_squint_score = max(0.0, min(1.0, (0.25 - avg_ear) * 10.0))

        # 3. ìµœì¢… ì ìˆ˜ ê³„ì‚° (ìµœì¢… ìŠ¤ì¼€ì¼ë§ ì†Œí­ ìƒí–¥ ì¡°ì •)
        # ê°€ì¤‘ì¹˜: ì… 70%, ëˆˆ 30% (ìœ ì§€)
        # (íŠœë‹ í•„ìš”)
        final_score = (mouth_score * 0.7 + eye_squint_score * 0.3) * 1.4

        return min(1.0, max(0.0, final_score)) # 0~1 ë²”ìœ„ í´ë¨í•‘

    def _measure_mouth_openness(self, landmarks):
        """ì… ë²Œë¦¼ ì •ë„ ì¸¡ì • - IOD ì •ê·œí™”, tanh í•¨ìˆ˜ ì ìš©, ìŠ¤ì¼€ì¼ë§ ì¶”ê°€ ì¡°ì • (ì ìˆ˜ ì†Œí­ ìƒí–¥)"""
        if landmarks is None or len(landmarks) < 68: return 0.0
        iod = self._calculate_iod(landmarks)

        # ì…ìˆ  ì•ˆìª½ ëœë“œë§ˆí¬ ì‚¬ìš© (61, 67 / 62, 66)
        inner_mouth_top = landmarks[62]
        inner_mouth_bottom = landmarks[66]
        mouth_height = hypot(inner_mouth_bottom[0] - inner_mouth_top[0], inner_mouth_bottom[1] - inner_mouth_top[1])

        # ì •ê·œí™”ëœ ì… ë†’ì´
        normalized_mouth_height = mouth_height / iod

        # tanh í•¨ìˆ˜ ì ìš© (ì…ë ¥ê°’ ìŠ¤ì¼€ì¼ë§ ë¯¸ì„¸ ìƒí–¥ ì¡°ì •)
        # (íŠœë‹) ìŠ¤ì¼€ì¼ë§ íŒ©í„° ì¦ê°€: 2.8 -> 3.1
        score = tanh(normalized_mouth_height * 3.1) # ì ìˆ˜ ì˜¬ë¦¬ê¸°

        return min(1.0, max(0.0, score)) # 0~1 ë²”ìœ„ í´ë¨í•‘

    def _measure_surprise(self, landmarks):
        """ë†€ëŒ ì •ë„ ì¸¡ì • - IOD ì •ê·œí™”, ëˆˆ/ëˆˆì¹ + ì… ë²Œë¦¼ ê³ ë ¤, ìŠ¤ì¼€ì¼ë§/ê°€ì¤‘ì¹˜ ë¯¸ì„¸ ì¡°ì • (ì ìˆ˜ ì†Œí­ ìƒí–¥)"""
        if landmarks is None or len(landmarks) < 68: return 0.0
        iod = self._calculate_iod(landmarks)

        # 1. ëˆˆì¹ & ëˆˆ íŠ¹ì§• ê³„ì‚°
        # ëˆˆì¹-ëˆˆ ê±°ë¦¬ (ëˆˆì¹ ì¤‘ì•™ê³¼ ëˆˆë™ì ìœ„ìª½ ëœë“œë§ˆí¬)
        left_brow_eye_dist = hypot(landmarks[19][0] - landmarks[37][0], landmarks[19][1] - landmarks[37][1]) # 19, 37
        right_brow_eye_dist = hypot(landmarks[24][0] - landmarks[43][0], landmarks[24][1] - landmarks[43][1]) # 24, 43
        # ëˆˆ ì„¸ë¡œ í¬ê¸° - EAR í™œìš©
        left_ear = self._calculate_ear(landmarks, self.L_EYE_START, self.L_EYE_END)
        right_ear = self._calculate_ear(landmarks, self.R_EYE_START, self.R_EYE_END)

        avg_brow_dist = (left_brow_eye_dist + right_brow_eye_dist) / 2
        avg_ear = (left_ear + right_ear) / 2.0

        # ì •ê·œí™” ë° ì ìˆ˜í™” (ìŠ¤ì¼€ì¼ë§ ì¸ì ìœ ì§€, EAR ê¸°ì¤€ ì¡°ì •)
        # (íŠœë‹ í•„ìš”) ëˆˆì¹-ëˆˆ ê±°ë¦¬ê°€ ë©€ì–´ì§ˆìˆ˜ë¡ ë†’ì€ ì ìˆ˜
        brow_score = min(1.0, max(0.0, (avg_brow_dist / iod - 0.4) * 5.0 )) # ê¸°ì¤€ 0.4, ìŠ¤ì¼€ì¼ 5
        # (íŠœë‹ í•„ìš”) ëˆˆì´ ì»¤ì§ˆìˆ˜ë¡(EAR ì¦ê°€) ë†’ì€ ì ìˆ˜
        eye_score = min(1.0, max(0.0, (avg_ear - 0.25) * 6.0)) # ê¸°ì¤€ 0.25, ìŠ¤ì¼€ì¼ 6

        # ëˆˆ/ëˆˆì¹ ì ìˆ˜ ê°€ì¤‘ í•©ì‚° (ê°€ì¤‘ì¹˜: ëˆˆì¹ 40%, ëˆˆ 60% ìœ ì§€)
        eye_brow_surprise_score = (brow_score * 0.4 + eye_score * 0.6)

        # 2. ì… ë²Œë¦¼ íŠ¹ì§• ê³„ì‚° (ìˆ˜ì •ëœ í•¨ìˆ˜ ì‚¬ìš©)
        mouth_openness_score = self._measure_mouth_openness(landmarks)

        # 3. ìµœì¢… ì ìˆ˜ ê³„ì‚° (ìµœì¢… ìŠ¤ì¼€ì¼ë§ ì†Œí­ ìƒí–¥ ì¡°ì •)
        # ê°€ì¤‘ì¹˜: ëˆˆ/ëˆˆì¹ 65%, ì… 35% (ìœ ì§€)
        # (íŠœë‹) ìµœì¢… ìŠ¤ì¼€ì¼ì—… ì¦ê°€: 1.35 -> 1.4
        final_score = (eye_brow_surprise_score * 0.65 + mouth_openness_score * 0.35) * 1.4 # ì ìˆ˜ ì˜¬ë¦¬ê¸°

        return min(1.0, max(0.0, final_score)) # 0~1 ë²”ìœ„ í´ë¨í•‘

    # --- ì¶”ê°€: ëª»ë‚œì´/ìš°ìŠ¤ê½ìŠ¤ëŸ¬ì›€ ì¸¡ì • í•¨ìˆ˜ (ì ìˆ˜ ì¶”ê°€ ì¡°ì •) ---
    def _measure_ugly_face(self, landmarks):
        """ìš°ìŠ¤ê½ìŠ¤ëŸ¬ìš´ í‘œì •(ë¹„ëŒ€ì¹­, ì°Œí‘¸ë¦¼ ë“±) ì¸¡ì • - ì ìˆ˜ ì¶”ê°€ ì¡°ì •"""
        if landmarks is None or len(landmarks) < 68: return 0.0
        iod = self._calculate_iod(landmarks)
        if iod <= 0: return 0.0 # IOD ìœ íš¨ì„± ì²´í¬

        # 1. ëˆˆ ë¹„ëŒ€ì¹­ì„± ì ìˆ˜ (ì¢Œìš° EAR ì°¨ì´) - ë¯¼ê°ë„ ì¶”ê°€ ì¦ê°€
        left_ear = self._calculate_ear(landmarks, self.L_EYE_START, self.L_EYE_END)
        right_ear = self._calculate_ear(landmarks, self.R_EYE_START, self.R_EYE_END)
        ear_diff = abs(left_ear - right_ear)
        # (íŠœë‹) ìŠ¤ì¼€ì¼ë§ íŒ©í„° ì¶”ê°€ ì¦ê°€: 6.0 -> 9.0
        eye_asymmetry_score = min(1.0, max(0.0, ear_diff * 9.0)) # ì ìˆ˜ ì˜¬ë¦¬ê¸° 1

        # 2. ì…ê¼¬ë¦¬ ë¹„ëŒ€ì¹­ì„± ì ìˆ˜ (Yì¢Œí‘œ ì°¨ì´ ì •ê·œí™”) - ë¯¼ê°ë„ ì¶”ê°€ ì¦ê°€
        mouth_left = landmarks[48]
        mouth_right = landmarks[54]
        corner_y_diff = abs(mouth_left[1] - mouth_right[1])
        normalized_corner_y_diff = corner_y_diff / iod
        # (íŠœë‹) ìŠ¤ì¼€ì¼ë§ íŒ©í„° ì¶”ê°€ ì¦ê°€: 6.0 -> 9.0
        mouth_asymmetry_score = min(1.0, max(0.0, normalized_corner_y_diff * 9.0)) # ì ìˆ˜ ì˜¬ë¦¬ê¸° 2

        # 3. ê³¼ë„í•œ ì°Œí‘¸ë¦¼ ì ìˆ˜ (ëˆˆì¹-ëˆˆ ê±°ë¦¬) - ë¯¼ê°ë„ ì¶”ê°€ ì¦ê°€
        left_brow_eye_dist = hypot(landmarks[21][0] - landmarks[39][0], landmarks[21][1] - landmarks[39][1])
        right_brow_eye_dist = hypot(landmarks[24][0] - landmarks[42][0], landmarks[24][1] - landmarks[42][1])
        avg_brow_dist = (left_brow_eye_dist + right_brow_eye_dist) / 2
        normalized_brow_dist = avg_brow_dist / iod
        # (íŠœë‹) ìŠ¤ì¼€ì¼ë§ íŒ©í„° ì¶”ê°€ ì¦ê°€: 10.0 -> 16.0
        frown_score = min(1.0, max(0.0, (0.25 - normalized_brow_dist) * 16.0)) # ì ìˆ˜ ì˜¬ë¦¬ê¸° 3

        # 4. ì¢…í•© ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ì¹˜ëŠ” ìœ ì§€, ìµœì¢… ìŠ¤ì¼€ì¼ì—… ì¶”ê°€ ì¦ê°€)
        # ê°€ì¤‘ì¹˜: ëˆˆ 30%, ì… 30%, ì°Œí‘¸ë¦¼ 40%
        # (íŠœë‹) ìµœì¢… ìŠ¤ì¼€ì¼ì—… ì¶”ê°€ ì¦ê°€: 1.2 -> 1.5
        total_score = (eye_asymmetry_score * 0.3 + mouth_asymmetry_score * 0.3 + frown_score * 0.4) * 1.5 # ì ìˆ˜ ì˜¬ë¦¬ê¸° 4

        # 5. ì¼ë°˜ì ì¸ í‘œì • ì ìˆ˜ ê°ì  (ì„ íƒì ) - í•„ìš”ì‹œ ì£¼ì„ í•´ì œ ë° íŠœë‹
        # smile_score = self._measure_smile(landmarks)
        # surprise_score = self._measure_surprise(landmarks)
        # if smile_score > 0.4 or surprise_score > 0.5:
        #     total_score *= 0.5

        return min(1.0, max(0.0, total_score)) # 0~1 ë²”ìœ„ í´ë¨í•‘

# CPU ë°”ìš´ë“œ ì‘ì—…ì„ ì²˜ë¦¬í•  ë™ê¸° í•¨ìˆ˜ (dlib ì˜ˆì¸¡)
def _run_dlib_prediction(frame_copy, face_x, face_y, face_w, face_h):
    """ì‹¤ì œ dlib ëœë“œë§ˆí¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” ë™ê¸° í•¨ìˆ˜"""
    if not dlib_available: return None
    try:
        # dlibì€ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©
        gray = cv2.cvtColor(frame_copy, cv2.COLOR_BGR2GRAY)
        rect = dlib.rectangle(int(face_x), int(face_y), int(face_x + face_w), int(face_y + face_h))

        shape = predictor(gray, rect)
        coords = np.zeros((68, 2), dtype=int)

        for i in range(0, 68):
            coords[i] = (shape.part(i).x, shape.part(i).y)

        return coords
    except Exception as e:
        # ì‹¤ì œ ìš´ì˜ ì‹œ ë¡œê¹… ë“±ìœ¼ë¡œ ëŒ€ì²´í•˜ëŠ” ê²ƒì´ ì¢‹ìŒ
        print(f"ëœë“œë§ˆí¬ ê°ì§€ ì˜¤ë¥˜ (ë™ê¸° í•¨ìˆ˜ ë‚´): {e}")
        return None

# ê¸°ì¡´ get_face_landmarks í•¨ìˆ˜ë¥¼ async í•¨ìˆ˜ë¡œ ë³€ê²½
async def get_face_landmarks(frame, face_x, face_y, face_w, face_h):
    """dlibë¥¼ ì‚¬ìš©í•´ ì–¼êµ´ ëœë“œë§ˆí¬ ì¶”ì¶œ (ë¹„ë™ê¸° ì‹¤í–‰)"""
    # í”„ë ˆì„ ë³µì‚¬ë³¸ ì „ë‹¬ (dlib ì²˜ë¦¬ë¥¼ ìœ„í•´ í•„ìš”í•  ìˆ˜ ìˆìŒ)
    landmarks = await asyncio.to_thread(
        _run_dlib_prediction, frame.copy(), face_x, face_y, face_w, face_h
    )
    return landmarks

async def apply_handpick_effect(frame, initial_faces, websocket, original_frame=None, is_running=lambda: True, animation_service=None, client_id=None):
    """í‘œì • ë³€í™”ë¥¼ ê°ì§€í•˜ì—¬ ë°œí‘œì ì„ ì • - ë…ë¦½ í”„ë ˆì„ ë°©ì‹"""
    if not dlib_available:
         await websocket.send_json({
            'type': 'error',
            'message': 'âŒ ì–¼êµ´ ëœë“œë§ˆí¬ ê°ì§€ê¸°(dlib)ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
        })
         return frame, None

    if len(initial_faces) == 0:
        await websocket.send_json({
            'type': 'error',
            'message': 'âŒ ê°ì§€ëœ ì–¼êµ´ì´ ì—†ìŠµë‹ˆë‹¤.'
        })
        return frame, None

    await websocket.send_json({'type': 'animation_start', 'mode': 'handpick'})

    # detection_mode ë¦¬ìŠ¤íŠ¸ì—ì„œ "refreshing_wink" ì œê±°
    detection_mode = random.choice(["open_mouth", "big_smile", "surprise", "ugly_face"])
    expression_detector = ExpressionDetector()

    await asyncio.sleep(1)
    await websocket.send_json({'type': 'handpick_start'})
    await websocket.send_json({'type': 'play_sound', 'sound': 'handpick/start'})

    # --- ì¹´ìš´íŠ¸ë‹¤ìš´ ---
    for countdown in range(5, 0, -1):
        if not is_running(): return frame, None
        # await websocket.send_json({'type': 'play_sound', 'sound': 'handpick/countdown'})
        faces_for_countdown = [] # ì¹´ìš´íŠ¸ë‹¤ìš´ ì¤‘ì—” ì–¼êµ´ ì •ë³´ ë¶ˆí•„ìš”
        await websocket.send_json({
            'type': 'handpick_progress',
            'faces': faces_for_countdown,
            'stage': 'start',
            'progress': (5 - countdown) / 5.0,
            'countdown': countdown,
            'expression_mode': detection_mode
        })
        await asyncio.sleep(1)

    # --- ì¶”ê°€: í‘œì • ê°ì§€ ì‹œì‘ ì‹œ ë°°ê²½ìŒì•… ì¬ìƒ ---
    await websocket.send_json({
        'type': 'play_sound',
        'sound': 'handpick/main',
        # 'options': {'loop': True} # ë£¨í”„ ì—¬ë¶€ëŠ” í•„ìš”ì‹œ í™œì„±í™”
    })
    # --- ì¶”ê°€ ë ---

    # --- ë³´ì • ë‹¨ê³„ (ë‹¨ìˆœíˆ ì´ˆê¸° í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°) ---
    baseline_frame = None
    if animation_service and client_id and client_id in animation_service.last_frames:
        baseline_frame = animation_service.last_frames[client_id].copy()
    else:
        baseline_frame = frame.copy() # Fallback

    # ì´ˆê¸° ì–¼êµ´ ê°ì§€ (í›„ì† ê°ì§€ ë£¨í”„ì˜ ì‹œì‘ì ) (ë¹„ë™ê¸° í˜¸ì¶œë¡œ ë³€ê²½)
    last_detected_faces = await detect_faces_yolo(baseline_frame) # await ì¶”ê°€
    if len(last_detected_faces) == 0:
        print("âš ï¸ ì´ˆê¸° í”„ë ˆì„ì—ì„œ ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨. í•¸ë“œí”½ ë¡œì§ ì¤‘ë‹¨ ê°€ëŠ¥ì„±.")
        last_detected_faces = initial_faces # ì¼ë‹¨ initial_facesë¡œ ì‹œë„

    await websocket.send_json({
        'type': 'handpick_calibration_complete', # ì´ë¦„ì€ ìœ ì§€í•˜ë˜, ì‹¤ì œ ë³´ì •ì€ ì—†ìŒ
        'expression_mode': detection_mode,
        'measurement_time': 10 # ì¸¡ì • ì‹œê°„ (ì´ˆ)
    })

    # --- í‘œì • ë³€í™” ê°ì§€ ë£¨í”„ (10ì´ˆ) ---
    detection_time = 10
    start_time = asyncio.get_event_loop().time()
    # last_detected_faces ëŠ” ìœ„ì—ì„œ ì´ˆê¸°í™”ë¨
    last_time_notice = -1

    while asyncio.get_event_loop().time() - start_time < detection_time:
        if not is_running(): return frame, None

        current_time = asyncio.get_event_loop().time()
        elapsed = current_time - start_time
        remaining = max(0, detection_time - elapsed)
        current_second = int(remaining)

        # ë‚¨ì€ ì‹œê°„ ì•Œë¦¼
        if current_second <= 3 and current_second != last_time_notice:
            last_time_notice = current_second
            if current_second > 0:
                await websocket.send_json({'type': 'play_sound', 'sound': 'handpick/countdown'})

        # ìµœì‹  í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°
        current_frame = None
        if animation_service and client_id and client_id in animation_service.last_frames:
            current_frame = animation_service.last_frames[client_id].copy()
        else:
             current_frame = baseline_frame # Fallback

        # ì‹¤ì‹œê°„ ì–¼êµ´ ê°ì§€ (ë¹„ë™ê¸° í˜¸ì¶œë¡œ ë³€ê²½)
        current_faces_in_loop = await detect_faces_yolo(current_frame) # await ì¶”ê°€

        if len(current_faces_in_loop) == 0: # í˜„ì¬ í”„ë ˆì„ì— ì–¼êµ´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
            await websocket.send_json({
                'type': 'handpick_progress',
                'faces': [], # ì–¼êµ´ ì—†ìŒ í‘œì‹œ
                'stage': 'waiting',
                'progress': min(1.0, elapsed / detection_time)
            })
            await asyncio.sleep(0.1)
            continue # ë‹¤ìŒ ë£¨í”„ ë°˜ë³µìœ¼ë¡œ

        last_detected_faces = current_faces_in_loop # ìœ íš¨í•œ ì–¼êµ´ ì •ë³´ ì—…ë°ì´íŠ¸

        # ì–¼êµ´ë³„ í‘œì • ì ìˆ˜ ê³„ì‚° (í˜„ì¬ í”„ë ˆì„ ê¸°ì¤€)
        face_data = []
        current_loop_max_score = 0.0
        current_loop_candidate_idx = -1
        has_candidates = False

        for idx, (x, y, w, h) in enumerate(current_faces_in_loop):
            # get_face_landmarks ë¹„ë™ê¸° í˜¸ì¶œë¡œ ë³€ê²½
            landmarks = await get_face_landmarks(current_frame, int(x), int(y), int(w), int(h)) # await ì¶”ê°€
            score = 0.0
            if landmarks is not None:
                # í˜„ì¬ í”„ë ˆì„ ì ìˆ˜ ê³„ì‚° (ëˆ„ì /ìŠ¤ë¬´ë”© ì—†ìŒ)
                score = expression_detector.get_expression_score(idx, landmarks, detection_mode)

                # í˜„ì¬ ë£¨í”„ ë‚´ ìµœê³  ì ìˆ˜ ì—…ë°ì´íŠ¸
                if score > current_loop_max_score:
                    current_loop_max_score = score
                    current_loop_candidate_idx = idx
                    has_candidates = True
            # else: score is 0.0

            # í´ë¼ì´ì–¸íŠ¸ ì „ì†¡ ë°ì´í„° êµ¬ì„± (í˜„ì¬ í”„ë ˆì„ ì •ë³´ë§Œ ì‚¬ìš©)
            face_data.append({
                "face": current_faces_in_loop[idx].tolist(),
                "expression_score": int(score * 100), # ì ìˆ˜ ìŠ¤ì¼€ì¼ 0-100
                "is_candidate": idx == current_loop_candidate_idx
            })

        # ì§„í–‰ ìƒí™© ì „ì†¡
        await websocket.send_json({
            'type': 'handpick_progress',
            'faces': face_data,
            'stage': 'detecting' if has_candidates else 'waiting',
            'progress': min(1.0, elapsed / detection_time)
        })

        await asyncio.sleep(0.1)

    # --- ë£¨í”„ ì¢…ë£Œ í›„ ìµœì¢… ì„ ì • ë¡œì§ ---
    print("Handpick ë£¨í”„ ì¢…ë£Œ, ìµœì¢… ì ìˆ˜ ê³„ì‚° ì‹œì‘")
    final_frame = None
    if animation_service and client_id and client_id in animation_service.last_frames:
        final_frame = animation_service.last_frames[client_id].copy()
    else:
        final_frame = current_frame if 'current_frame' in locals() else baseline_frame

    # final_frame ìœ íš¨ì„± ì²´í¬
    if final_frame is None:
         await websocket.send_json({'type': 'error', 'message': 'âŒ ìµœì¢… ê²°ê³¼ í”„ë ˆì„ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'})
         return frame, None

    final_faces_for_ranking = last_detected_faces
    print(f"ìµœì¢… í”„ë ˆì„ ì–¼êµ´ ê°ì§€ ê²°ê³¼: {len(final_faces_for_ranking)} ëª…")

    final_scores_calculated = {}

    if len(final_faces_for_ranking) == 0:
         await websocket.send_json({'type': 'error', 'message': 'âŒ ìµœì¢… ì„ ì • ì‹œì ì— ê°ì§€ëœ ì–¼êµ´ì´ ì—†ìŠµë‹ˆë‹¤.'})
         return frame, None
    else:
        # ë§ˆì§€ë§‰ í”„ë ˆì„ ê¸°ì¤€ìœ¼ë¡œ ì ìˆ˜ ê³„ì‚° (ìŠ¤ë¬´ë”© ì—†ìŒ)
        for idx, (x, y, w, h) in enumerate(final_faces_for_ranking):
            # get_face_landmarks ë¹„ë™ê¸° í˜¸ì¶œë¡œ ë³€ê²½
            final_landmarks = await get_face_landmarks(final_frame, int(x), int(y), int(w), int(h)) # await ì¶”ê°€
            final_score = 0.0
            if final_landmarks is not None:
                final_score = expression_detector.get_expression_score(idx, final_landmarks, detection_mode)

            final_scores_calculated[idx] = final_score


    # ìµœì¢… ì ìˆ˜ ê¸°ë°˜ ìˆœìœ„ ì„ ì •
    all_scores = [{"idx": idx, "score": score} for idx, score in final_scores_calculated.items()]
    all_scores.sort(key=lambda x: x["score"], reverse=True)

    selected_face_coords = None
    best_score = 0.0
    best_idx = -1

    # ì„ ì • ê¸°ì¤€ ì ìˆ˜ (íŠœë‹ í•„ìš”)
    MIN_VALID_SCORE = 0.2 # ìš°ì„  ê³µí†µ ê¸°ì¤€ ì‚¬ìš©

    if all_scores and all_scores[0]["score"] >= MIN_VALID_SCORE:
        best_idx = all_scores[0]["idx"]
        best_score = all_scores[0]["score"]
        # ì¸ë±ìŠ¤ ìœ íš¨ì„± ê²€ì‚¬ ê°•í™”
        if best_idx < len(final_faces_for_ranking):
             selected_face_coords = final_faces_for_ranking[best_idx]
             print(f"ìµœì¢… ì„ ì •: ì–¼êµ´ #{best_idx}, ì ìˆ˜: {best_score:.2f}")
        else:
             best_idx = -1
             print(f"âš ï¸ ì¸ë±ìŠ¤ ì˜¤ë¥˜ ë°œìƒ: best_idx={best_idx}, final_faces_for_ranking ê¸¸ì´={len(final_faces_for_ranking)}")


    # ê¸°ì¤€ ë¯¸ë‹¬ ë˜ëŠ” ìœ íš¨ ì„ ì •ì ì—†ìœ¼ë©´ ëœë¤ ì„ íƒ
    if selected_face_coords is None:
        print(f"ìœ íš¨ ì ìˆ˜ ë¯¸ë‹¬ ë˜ëŠ” ì„ ì •ì ì—†ìŒ (ìµœê³ ì ìˆ˜: {all_scores[0]['score'] if all_scores else 'N/A'}). ëœë¤ ì„ ì • ì‹¤í–‰.")
        if len(final_faces_for_ranking) > 0:
            best_idx = random.randrange(len(final_faces_for_ranking))
            selected_face_coords = final_faces_for_ranking[best_idx]
            # ëœë¤ ì„ íƒ ì‹œ ì ìˆ˜ë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ê³  all_scores ì—…ë°ì´íŠ¸
            for entry in all_scores:
                if entry["idx"] == best_idx: entry["score"] = 0.0
            else: all_scores.append({"idx": best_idx, "score": 0.0})
            all_scores.sort(key=lambda x: x["score"], reverse=True)
            print(f"ëœë¤ ì„ ì •: ì–¼êµ´ #{best_idx}")
        else:
            await websocket.send_json({'type': 'error', 'message': 'âŒ ìµœì¢… ì„ ì • ì‹œì ì— ê°ì§€ëœ ì–¼êµ´ì´ ì—†ìŠµë‹ˆë‹¤.'})
            return frame, None

    # --- ê²°ê³¼ ì „ì†¡ ë°ì´í„° êµ¬ì„± ---
    expression_name = ""
    message = "ğŸ­ ì—°ê¸°ëŒ€ìƒ ì„ ì •!"
    final_score_for_message = int(all_scores[0]["score"] * 100) if all_scores else 0

    if best_score >= MIN_VALID_SCORE: # ìœ íš¨ ì ìˆ˜ë¡œ ì„ ì •ëœ ê²½ìš°
        if detection_mode == "smile" or detection_mode == "big_smile":
            expression_name = "ë°ì€ ë¯¸ì†Œ"
            message = f"ìµœê³  ì ìˆ˜: {final_score_for_message}ì "
        elif detection_mode == "open_mouth":
            expression_name = "ë†€ë¼ìš´ í•œì…"
            message = f"ìµœê³  ì ìˆ˜: {final_score_for_message}ì "
        elif detection_mode == "surprise":
            expression_name = "ê·¹ì ì¸ ë†€ëŒ"
            message = f"ìµœê³  ì ìˆ˜: {final_score_for_message}ì "
        elif detection_mode == "ugly_face":
            expression_name = "ì˜¤ëŠ˜ì˜ ëª»ë‚œì´"
            message = f"ìµœê³  ì ìˆ˜: {final_score_for_message}ì "
    else: # ëœë¤ ì„ ì •ëœ ê²½ìš°
        expression_name = "ëœë¤ ì„ ì •"
        message = "í–‰ìš´ì˜ ì£¼ì¸ê³µ!"


    # ìƒìœ„ 3ëª… ìˆœìœ„ ì •ë³´ êµ¬ì„± (ìˆ˜ì •: 5ëª… -> 3ëª…)
    ranking_data = []
    for rank, entry in enumerate(all_scores[:3]):
        if entry["idx"] < len(final_faces_for_ranking):
            rank_info = {
                "face": final_faces_for_ranking[entry["idx"]].tolist(),
                "rank": rank + 1,
                "score": int(entry["score"] * 100) # 0-100 ìŠ¤ì¼€ì¼
            }
            ranking_data.append(rank_info)

    # ìµœì¢… í”„ë ˆì„ Base64 ì¸ì½”ë”©
    result_frame_base64 = None
    try:
        _, buffer = cv2.imencode('.jpg', final_frame)
        result_frame_base64 = base64.b64encode(buffer).decode('utf-8')
    except Exception as e:
        print(f"Error encoding final frame: {e}")

    # --- ì¶”ê°€: ê²°ê³¼ ë°œí‘œ ì „ ë°°ê²½ìŒì•… ì¤‘ì§€ ---
    await websocket.send_json({'type': 'stop_sound', 'sound': 'handpick/main'})
    # --- ì¶”ê°€ ë ---
    # ê²°ê³¼ ë°œí‘œ ì‚¬ìš´ë“œ
    await websocket.send_json({'type': 'play_sound', 'sound': 'handpick/result'})

    # ìµœì¢… ê²°ê³¼ ì „ì†¡
    await websocket.send_json({
        'type': 'handpick_result',
        'face': selected_face_coords.tolist() if selected_face_coords is not None else None,
        'expression_name': expression_name,
        'message': message,
        'ranking': ranking_data,
        'result_frame': result_frame_base64
    })

    await websocket.send_json({'type': 'selection_complete', 'mode': 'handpick'})

    return frame, selected_face_coords
